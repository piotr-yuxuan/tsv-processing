DependencyName,DependencyPath,Description,License,Md5,Sha1,Identifiers,CPE,CVE,CWE,Vulnerability,Source,CVSSv2_Severity,CVSSv2_Score,CVSSv2,CVSSv3_BaseSeverity,CVSSv3_BaseScore,CVSSv3,CVSSv4_BaseSeverity,CVSSv4_BaseScore,CVSSv4,CPE Confidence,Evidence Count,VendorProject,Product,Name,DateAdded,ShortDescription,RequiredAction,DueDate,Notes
avro-1.9.2.jar,/home/runner/.m2/repository/org/apache/avro/avro/1.9.2/avro-1.9.2.jar,Avro core components,https://www.apache.org/licenses/LICENSE-2.0.txt,cb70195f70f52b27070f9359b77690bb,7e67193b94e45d32277ac480ea86421fd3976424,pkg:maven/org.apache.avro/avro@1.9.2,,CVE-2024-47561,CWE-502 Deserialization of Untrusted Data,"Schema parsing in the Java SDK of Apache Avro 1.11.3 and previous versions allows bad actors to execute arbitrary code. Users are recommended to upgrade to version 1.11.4  or 1.12.0, which fix this issue.",OSSINDEX,HIGH,9.300000190734863,CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:H/VI:H/VA:H/SC:N/SI:N/SA:N,,,,,,,HIGH,34,,,,,,,,
avro-1.9.2.jar,/home/runner/.m2/repository/org/apache/avro/avro/1.9.2/avro-1.9.2.jar,Avro core components,https://www.apache.org/licenses/LICENSE-2.0.txt,cb70195f70f52b27070f9359b77690bb,7e67193b94e45d32277ac480ea86421fd3976424,pkg:maven/org.apache.avro/avro@1.9.2,,CVE-2023-39410,CWE-502 Deserialization of Untrusted Data,"When deserializing untrusted or corrupted data, it is possible for a reader to consume memory beyond the allowed constraints and thus lead to out of memory on the system.  This issue affects Java applications using Apache Avro Java SDK up to and including 1.11.2.  Users should update to apache-avro version 1.11.3 which addresses this issue.",OSSINDEX,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H,,,,HIGH,34,,,,,,,,
clojure-1.11.1.jar,/home/runner/.m2/repository/org/clojure/clojure/1.11.1/clojure-1.11.1.jar,Clojure core environment and runtime library.,Eclipse Public License 1.0: http://opensource.org/licenses/eclipse-1.0.php,88321e4272aa5e10d2b803f47944e27c,2896bc72c90da8125026c0e61df0470a084f9ec3,pkg:maven/org.clojure/clojure@1.11.1,cpe:2.3:a:clojure:clojure:1.11.1:*:*:*:*:*:*:*,CVE-2024-22871,CWE-502 Deserialization of Untrusted Data,An issue in Clojure versions 1.20 to 1.12.0-alpha5 allows an attacker to cause a denial of service (DoS) via the clojure.core$partial$fn__5920 function.,NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,21,,,,,,,,
commons-compress-1.19.jar,/home/runner/.m2/repository/org/apache/commons/commons-compress/1.19/commons-compress-1.19.jar,"Apache Commons Compress software defines an API for working with compression and archive formats.  These include: bzip2, gzip, pack200, lzma, xz, Snappy, traditional Unix Compress, DEFLATE, DEFLATE64, LZ4, Brotli, Zstandard and ar, cpio, jar, tar, zip, dump, 7z, arj.",https://www.apache.org/licenses/LICENSE-2.0.txt,fe897bced43468450b785b66c1cff455,7e65777fb451ddab6a9c054beb879e521b7eab78,pkg:maven/org.apache.commons/commons-compress@1.19,cpe:2.3:a:apache:commons_compress:1.19:*:*:*:*:*:*:*,CVE-2021-35515,"CWE-834 Excessive Iteration, CWE-835 Loop with Unreachable Exit Condition ('Infinite Loop')","When reading a specially crafted 7Z archive, the construction of the list of codecs that decompress an entry can result in an infinite loop. This could be used to mount a denial of service attack against services that use Compress' sevenz package.",NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,94,,,,,,,,
commons-compress-1.19.jar,/home/runner/.m2/repository/org/apache/commons/commons-compress/1.19/commons-compress-1.19.jar,"Apache Commons Compress software defines an API for working with compression and archive formats.  These include: bzip2, gzip, pack200, lzma, xz, Snappy, traditional Unix Compress, DEFLATE, DEFLATE64, LZ4, Brotli, Zstandard and ar, cpio, jar, tar, zip, dump, 7z, arj.",https://www.apache.org/licenses/LICENSE-2.0.txt,fe897bced43468450b785b66c1cff455,7e65777fb451ddab6a9c054beb879e521b7eab78,pkg:maven/org.apache.commons/commons-compress@1.19,cpe:2.3:a:apache:commons_compress:1.19:*:*:*:*:*:*:*,CVE-2021-35516,"CWE-130 Improper Handling of Length Parameter Inconsistency, CWE-770 Allocation of Resources Without Limits or Throttling","When reading a specially crafted 7Z archive, Compress can be made to allocate large amounts of memory that finally leads to an out of memory error even for very small inputs. This could be used to mount a denial of service attack against services that use Compress' sevenz package.",NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,94,,,,,,,,
commons-compress-1.19.jar,/home/runner/.m2/repository/org/apache/commons/commons-compress/1.19/commons-compress-1.19.jar,"Apache Commons Compress software defines an API for working with compression and archive formats.  These include: bzip2, gzip, pack200, lzma, xz, Snappy, traditional Unix Compress, DEFLATE, DEFLATE64, LZ4, Brotli, Zstandard and ar, cpio, jar, tar, zip, dump, 7z, arj.",https://www.apache.org/licenses/LICENSE-2.0.txt,fe897bced43468450b785b66c1cff455,7e65777fb451ddab6a9c054beb879e521b7eab78,pkg:maven/org.apache.commons/commons-compress@1.19,cpe:2.3:a:apache:commons_compress:1.19:*:*:*:*:*:*:*,CVE-2021-35517,"CWE-130 Improper Handling of Length Parameter Inconsistency, CWE-770 Allocation of Resources Without Limits or Throttling","When reading a specially crafted TAR archive, Compress can be made to allocate large amounts of memory that finally leads to an out of memory error even for very small inputs. This could be used to mount a denial of service attack against services that use Compress' tar package.",NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,94,,,,,,,,
commons-compress-1.19.jar,/home/runner/.m2/repository/org/apache/commons/commons-compress/1.19/commons-compress-1.19.jar,"Apache Commons Compress software defines an API for working with compression and archive formats.  These include: bzip2, gzip, pack200, lzma, xz, Snappy, traditional Unix Compress, DEFLATE, DEFLATE64, LZ4, Brotli, Zstandard and ar, cpio, jar, tar, zip, dump, 7z, arj.",https://www.apache.org/licenses/LICENSE-2.0.txt,fe897bced43468450b785b66c1cff455,7e65777fb451ddab6a9c054beb879e521b7eab78,pkg:maven/org.apache.commons/commons-compress@1.19,cpe:2.3:a:apache:commons_compress:1.19:*:*:*:*:*:*:*,CVE-2021-36090,"CWE-130 Improper Handling of Length Parameter Inconsistency, NVD-CWE-Other","When reading a specially crafted ZIP archive, Compress can be made to allocate large amounts of memory that finally leads to an out of memory error even for very small inputs. This could be used to mount a denial of service attack against services that use Compress' zip package.",NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,94,,,,,,,,
commons-compress-1.19.jar,/home/runner/.m2/repository/org/apache/commons/commons-compress/1.19/commons-compress-1.19.jar,"Apache Commons Compress software defines an API for working with compression and archive formats.  These include: bzip2, gzip, pack200, lzma, xz, Snappy, traditional Unix Compress, DEFLATE, DEFLATE64, LZ4, Brotli, Zstandard and ar, cpio, jar, tar, zip, dump, 7z, arj.",https://www.apache.org/licenses/LICENSE-2.0.txt,fe897bced43468450b785b66c1cff455,7e65777fb451ddab6a9c054beb879e521b7eab78,pkg:maven/org.apache.commons/commons-compress@1.19,cpe:2.3:a:apache:commons_compress:1.19:*:*:*:*:*:*:*,CVE-2024-25710,CWE-835 Loop with Unreachable Exit Condition ('Infinite Loop'),Loop with Unreachable Exit Condition ('Infinite Loop') vulnerability in Apache Commons Compress.This issue affects Apache Commons Compress: from 1.3 through 1.25.0.  Users are recommended to upgrade to version 1.26.0 which fixes the issue.,NVD,,,,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H/E:1.8/RC:R/MAV:A,,,,HIGH,94,,,,,,,,
connect-api-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/connect-api/2.8.0/connect-api-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",482a7fe3fbf9207eb21a450e894cdcc9,33886f7e3d640bfc867f8bb635e37e777c4161d0,pkg:maven/org.apache.kafka/connect-api@2.8.0,"cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:kafka_connect:2.8.0:*:*:*:*:*:*:*",CVE-2023-25194,CWE-502 Deserialization of Untrusted Data,"A possible security vulnerability has been identified in Apache Kafka Connect API. This requires access to a Kafka Connect worker, and the ability to create/modify connectors on it with an arbitrary Kafka client SASL JAAS config and a SASL-based security protocol, which has been possible on Kafka Connect clusters since Apache Kafka Connect 2.3.0. When configuring the connector via the Kafka Connect REST API, an authenticated operator can set the `sasl.jaas.config` property for any of the connector's Kafka clients to ""com.sun.security.auth.module.JndiLoginModule"", which can be done via the `producer.override.sasl.jaas.config`, `consumer.override.sasl.jaas.config`, or `admin.override.sasl.jaas.config` properties. This will allow the server to connect to the attacker's LDAP server and deserialize the LDAP response, which the attacker can use to execute java deserialization gadget chains on the Kafka connect server. Attacker can cause unrestricted deserialization of untrusted data (or) RCE vulnerability when there are gadgets in the classpath.  Since Apache Kafka 3.0.0, users are allowed to specify these properties in connector configurations for Kafka Connect clusters running with out-of-the-box configurations. Before Apache Kafka 3.0.0, users may not specify these properties unless the Kafka Connect cluster has been reconfigured with a connector client override policy that permits them.  Since Apache Kafka 3.4.0, we have added a system property (""-Dorg.apache.kafka.disallowed.login.modules"") to disable the problematic login modules usage in SASL JAAS configuration. Also by default ""com.sun.security.auth.module.JndiLoginModule"" is disabled in Apache Kafka Connect 3.4.0.   We advise the Kafka Connect users to validate connector configurations and only allow trusted JNDI configurations. Also examine connector dependencies for  vulnerable versions and either upgrade their connectors, upgrading that specific dependency, or removing the connectors as options for remediation. Finally, in addition to leveraging the ""org.apache.kafka.disallowed.login.modules"" system property, Kafka Connect users can also implement their own connector client config override policy, which can be used to control which Kafka client properties can be overridden directly in a connector config and which cannot.",NVD,,,,HIGH,8.8,CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H/E:2.8/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
connect-api-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/connect-api/2.8.0/connect-api-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",482a7fe3fbf9207eb21a450e894cdcc9,33886f7e3d640bfc867f8bb635e37e777c4161d0,pkg:maven/org.apache.kafka/connect-api@2.8.0,"cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:kafka_connect:2.8.0:*:*:*:*:*:*:*",CVE-2022-34917,"CWE-789 Memory Allocation with Excessive Size Value, CWE-770 Allocation of Resources Without Limits or Throttling","A security vulnerability has been identified in Apache Kafka. It affects all releases since 2.8.0. The vulnerability allows malicious unauthenticated clients to allocate large amounts of memory on brokers. This can lead to brokers hitting OutOfMemoryException and causing denial of service. Example scenarios: - Kafka cluster without authentication: Any clients able to establish a network connection to a broker can trigger the issue. - Kafka cluster with SASL authentication: Any clients able to establish a network connection to a broker, without the need for valid SASL credentials, can trigger the issue. - Kafka cluster with TLS authentication: Only clients able to successfully authenticate via TLS can trigger the issue. We advise the users to upgrade the Kafka installations to one of the 3.2.3, 3.1.2, 3.0.2, 2.8.2 versions.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
connect-api-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/connect-api/2.8.0/connect-api-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",482a7fe3fbf9207eb21a450e894cdcc9,33886f7e3d640bfc867f8bb635e37e777c4161d0,pkg:maven/org.apache.kafka/connect-api@2.8.0,"cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:kafka_connect:2.8.0:*:*:*:*:*:*:*",CVE-2021-38153,CWE-203 Observable Discrepancy,"Some components in Apache Kafka use `Arrays.equals` to validate a password or key, which is vulnerable to timing attacks that make brute force attacks for such credentials more likely to be successful. Users should upgrade to 2.8.1 or higher, or 3.0.0 or higher where this vulnerability has been fixed. The affected versions include Apache Kafka 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.6.1, 2.6.2, 2.7.0, 2.7.1, and 2.8.0.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.9,CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N/E:2.2/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
connect-api-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/connect-api/2.8.0/connect-api-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",482a7fe3fbf9207eb21a450e894cdcc9,33886f7e3d640bfc867f8bb635e37e777c4161d0,pkg:maven/org.apache.kafka/connect-api@2.8.0,"cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:kafka_connect:2.8.0:*:*:*:*:*:*:*",CVE-2024-56128,"CWE-303 Incorrect Implementation of Authentication Algorithm, NVD-CWE-Other","Incorrect Implementation of Authentication Algorithm in Apache Kafka's SCRAM implementation.  Issue Summary: Apache Kafka's implementation of the Salted Challenge Response Authentication Mechanism (SCRAM) did not fully adhere to the requirements of RFC 5802 [1]. Specifically, as per RFC 5802, the server must verify that the nonce sent by the client in the second message matches the nonce sent by the server in its first message. However, Kafka's SCRAM implementation did not perform this validation.  Impact: This vulnerability is exploitable only when an attacker has plaintext access to the SCRAM authentication exchange. However, the usage of SCRAM over plaintext is strongly discouraged as it is considered an insecure practice [2]. Apache Kafka recommends deploying SCRAM exclusively with TLS encryption to protect SCRAM exchanges from interception [3]. Deployments using SCRAM with TLS are not affected by this issue.  How to Detect If You Are Impacted: If your deployment uses SCRAM authentication over plaintext communication channels (without TLS encryption), you are likely impacted. To check if TLS is enabled, review your server.properties configuration file for listeners property. If you have SASL_PLAINTEXT in the listeners, then you are likely impacted.  Fix Details: The issue has been addressed by introducing nonce verification in the final message of the SCRAM authentication exchange to ensure compliance with RFC 5802.  Affected Versions: Apache Kafka versions 0.10.2.0 through 3.9.0, excluding the fixed versions below.  Fixed Versions: 3.9.0 3.8.1 3.7.2  Users are advised to upgrade to 3.7.2 or later to mitigate this issue.  Recommendations for Mitigation: Users unable to upgrade to the fixed versions can mitigate the issue by: - Using TLS with SCRAM Authentication: Always deploy SCRAM over TLS to encrypt authentication exchanges and protect against interception. - Considering Alternative Authentication Mechanisms: Evaluate alternative authentication mechanisms, such as PLAIN, Kerberos or OAuth with TLS, which provide additional layers of security.",NVD,,,,MEDIUM,5.3,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N/E:3.9/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
jackson-core-2.10.2.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.10.2/jackson-core-2.10.2.jar,"Core Jackson processing abstractions (aka Streaming API), implementation for JSON",http://www.apache.org/licenses/LICENSE-2.0.txt,5514a46e38331f8c8262ea63bf36483e,73d4322a6bda684f676a2b5fe918361c4e5c7cca,pkg:maven/com.fasterxml.jackson.core/jackson-core@2.10.2,cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.2:*:*:*:*:*:*:*,CVE-2025-52999,CWE-121 Stack-based Buffer Overflow,"jackson-core contains core low-level incremental (""streaming"") parser and generator abstractions used by Jackson Data Processor. In versions prior to 2.15.0, if a user parses an input file and it has deeply nested data, Jackson could end up throwing a StackoverflowError if the depth is particularly large. jackson-core 2.15.0 contains a configurable limit for how deep Jackson will traverse in an input document, defaulting to an allowable depth of 1000. jackson-core will throw a StreamConstraintsException if the limit is reached. jackson-databind also benefits from this change because it uses jackson-core to parse JSON inputs. As a workaround, users should avoid parsing input files from untrusted sources.",OSSINDEX,HIGH,8.699999809265137,CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:N/VI:N/VA:H/SC:N/SI:N/SA:N,,,,,,,HIGH,42,,,,,,,,
jackson-core-2.10.2.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.10.2/jackson-core-2.10.2.jar,"Core Jackson processing abstractions (aka Streaming API), implementation for JSON",http://www.apache.org/licenses/LICENSE-2.0.txt,5514a46e38331f8c8262ea63bf36483e,73d4322a6bda684f676a2b5fe918361c4e5c7cca,pkg:maven/com.fasterxml.jackson.core/jackson-core@2.10.2,cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.2:*:*:*:*:*:*:*,CVE-2025-49128,CWE-209 Generation of Error Message Containing Sensitive Information,"Jackson-core contains core low-level incremental (""streaming"") parser and generator abstractions used by Jackson Data Processor. Starting in version 2.0.0 and prior to version 2.13.0, a flaw in jackson-core's `JsonLocation._appendSourceDesc` method allows up to 500 bytes of unintended memory content to be included in exception messages. When parsing JSON from a byte array with an offset and length, the exception message incorrectly reads from the beginning of the array instead of the logical payload start. This results in possible information disclosure in systems using pooled or reused buffers, like Netty or Vert.x. This issue was silently fixed in jackson-core version 2.13.0, released on September 30, 2021, via PR #652. All users should upgrade to version 2.13.0 or later. If upgrading is not immediately possible, applications can mitigate the issue by disabling exception message exposure to clients to avoid returning parsing exception messages in HTTP responses and/or disabling source inclusion in exceptions to prevent Jackson from embedding any source content in exception messages, avoiding leakage.  Sonatype's research suggests that this CVE's details differ from those defined at NVD. See https://ossindex.sonatype.org/vulnerability/CVE-2025-49128 for details",OSSINDEX,MEDIUM,6.900000095367432,CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:N/VA:N/SC:N/SI:N/SA:N,,,,,,,HIGH,42,,,,,,,,
jackson-databind-2.10.5.1.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar,General data-binding functionality for Jackson: works on core streaming API,http://www.apache.org/licenses/LICENSE-2.0.txt,3aec7825a3153ea9d62582e1f6efea0b,7ff756c3af1fe95cb3cddba9158fc3289ca06387,pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.5.1,"cpe:2.3:a:fasterxml:jackson-databind:2.10.5.1:*:*:*:*:*:*:*, cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.5.1:*:*:*:*:*:*:*",CVE-2020-36518,CWE-787 Out-of-bounds Write,jackson-databind before 2.13.0 allows a Java StackOverflow exception and denial of service via a large depth of nested objects.,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,39,,,,,,,,
jackson-databind-2.10.5.1.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar,General data-binding functionality for Jackson: works on core streaming API,http://www.apache.org/licenses/LICENSE-2.0.txt,3aec7825a3153ea9d62582e1f6efea0b,7ff756c3af1fe95cb3cddba9158fc3289ca06387,pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.5.1,"cpe:2.3:a:fasterxml:jackson-databind:2.10.5.1:*:*:*:*:*:*:*, cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.5.1:*:*:*:*:*:*:*",CVE-2021-46877,CWE-770 Allocation of Resources Without Limits or Throttling,jackson-databind 2.10.x through 2.12.x before 2.12.6 and 2.13.x before 2.13.1 allows attackers to cause a denial of service (2 GB transient heap usage per read) in uncommon situations involving JsonNode JDK serialization.,NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,39,,,,,,,,
jackson-databind-2.10.5.1.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar,General data-binding functionality for Jackson: works on core streaming API,http://www.apache.org/licenses/LICENSE-2.0.txt,3aec7825a3153ea9d62582e1f6efea0b,7ff756c3af1fe95cb3cddba9158fc3289ca06387,pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.5.1,"cpe:2.3:a:fasterxml:jackson-databind:2.10.5.1:*:*:*:*:*:*:*, cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.5.1:*:*:*:*:*:*:*",CVE-2022-42003,CWE-502 Deserialization of Untrusted Data,"In FasterXML jackson-databind before versions 2.13.4.1 and 2.12.17.1, resource exhaustion can occur because of a lack of a check in primitive value deserializers to avoid deep wrapper array nesting, when the UNWRAP_SINGLE_VALUE_ARRAYS feature is enabled.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,39,,,,,,,,
jackson-databind-2.10.5.1.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar,General data-binding functionality for Jackson: works on core streaming API,http://www.apache.org/licenses/LICENSE-2.0.txt,3aec7825a3153ea9d62582e1f6efea0b,7ff756c3af1fe95cb3cddba9158fc3289ca06387,pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.5.1,"cpe:2.3:a:fasterxml:jackson-databind:2.10.5.1:*:*:*:*:*:*:*, cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.5.1:*:*:*:*:*:*:*",CVE-2022-42004,CWE-502 Deserialization of Untrusted Data,"In FasterXML jackson-databind before 2.13.4, resource exhaustion can occur because of a lack of a check in BeanDeserializer._deserializeFromArray to prevent use of deeply nested arrays. An application is vulnerable only with certain customized choices for deserialization.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,39,,,,,,,,
jackson-databind-2.10.5.1.jar,/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar,General data-binding functionality for Jackson: works on core streaming API,http://www.apache.org/licenses/LICENSE-2.0.txt,3aec7825a3153ea9d62582e1f6efea0b,7ff756c3af1fe95cb3cddba9158fc3289ca06387,pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.5.1,"cpe:2.3:a:fasterxml:jackson-databind:2.10.5.1:*:*:*:*:*:*:*, cpe:2.3:a:fasterxml:jackson-modules-java8:2.10.5.1:*:*:*:*:*:*:*",CVE-2023-35116,CWE-770 Allocation of Resources Without Limits or Throttling,"jackson-databind through 2.15.2 allows attackers to cause a denial of service or other unspecified impact via a crafted object that uses cyclic dependencies. NOTE: the vendor's perspective is that this is not a valid vulnerability report, because the steps of constructing a cyclic data structure and trying to serialize it cannot be achieved by an external attacker.",NVD,,,,MEDIUM,4.7,CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:H/E:1.0/RC:R/MAV:A,,,,HIGH,39,,,,,,,,
jersey-common-2.31.jar,/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.31/jersey-common-2.31.jar,Jersey core common packages,"EPL 2.0: http://www.eclipse.org/legal/epl-2.0 The GNU General Public License (GPL), Version 2, With Classpath Exception: https://www.gnu.org/software/classpath/license.html Apache License, 2.0: http://www.apache.org/licenses/LICENSE-2.0.html Public Domain: https://creativecommons.org/publicdomain/zero/1.0/",4e155dab61f8761a081969692e3d4d41,b918c028c3c8c8b92a1ebb764571c369a85de04b,pkg:maven/org.glassfish.jersey.core/jersey-common@2.31,cpe:2.3:a:jersey_project:jersey:2.31:*:*:*:*:*:*:*,CVE-2021-28168,CWE-378 Creation of Temporary File With Insecure Permissions,"Eclipse Jersey 2.28 to 2.33 and Eclipse Jersey 3.0.0 to 3.0.1 contains a local information disclosure vulnerability. This is due to the use of the File.createTempFile which creates a file inside of the system temporary directory with the permissions: -rw-r--r--. Thus the contents of this file are viewable by all other users locally on the system. As such, if the contents written is security sensitive, it can be disclosed to other local users.",OSSINDEX,,,,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N,,,,HIGH,29,,,,,,,,
kafka-clients-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",e57ddd02a349770f42d4019e85097dc8,a4f66ca79617470d1355b809675313619bbae45a,pkg:maven/org.apache.kafka/kafka-clients@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2023-25194,CWE-502 Deserialization of Untrusted Data,"A possible security vulnerability has been identified in Apache Kafka Connect API. This requires access to a Kafka Connect worker, and the ability to create/modify connectors on it with an arbitrary Kafka client SASL JAAS config and a SASL-based security protocol, which has been possible on Kafka Connect clusters since Apache Kafka Connect 2.3.0. When configuring the connector via the Kafka Connect REST API, an authenticated operator can set the `sasl.jaas.config` property for any of the connector's Kafka clients to ""com.sun.security.auth.module.JndiLoginModule"", which can be done via the `producer.override.sasl.jaas.config`, `consumer.override.sasl.jaas.config`, or `admin.override.sasl.jaas.config` properties. This will allow the server to connect to the attacker's LDAP server and deserialize the LDAP response, which the attacker can use to execute java deserialization gadget chains on the Kafka connect server. Attacker can cause unrestricted deserialization of untrusted data (or) RCE vulnerability when there are gadgets in the classpath.  Since Apache Kafka 3.0.0, users are allowed to specify these properties in connector configurations for Kafka Connect clusters running with out-of-the-box configurations. Before Apache Kafka 3.0.0, users may not specify these properties unless the Kafka Connect cluster has been reconfigured with a connector client override policy that permits them.  Since Apache Kafka 3.4.0, we have added a system property (""-Dorg.apache.kafka.disallowed.login.modules"") to disable the problematic login modules usage in SASL JAAS configuration. Also by default ""com.sun.security.auth.module.JndiLoginModule"" is disabled in Apache Kafka Connect 3.4.0.   We advise the Kafka Connect users to validate connector configurations and only allow trusted JNDI configurations. Also examine connector dependencies for  vulnerable versions and either upgrade their connectors, upgrading that specific dependency, or removing the connectors as options for remediation. Finally, in addition to leveraging the ""org.apache.kafka.disallowed.login.modules"" system property, Kafka Connect users can also implement their own connector client config override policy, which can be used to control which Kafka client properties can be overridden directly in a connector config and which cannot.   Sonatype's research suggests that this CVE's details differ from those defined at NVD. See https://ossindex.sonatype.org/vulnerability/CVE-2023-25194 for details",OSSINDEX,,,,HIGH,8.800000190734863,CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H,,,,HIGH,23,,,,,,,,
kafka-clients-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",e57ddd02a349770f42d4019e85097dc8,a4f66ca79617470d1355b809675313619bbae45a,pkg:maven/org.apache.kafka/kafka-clients@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2025-27818,CWE-502 Deserialization of Untrusted Data,"A possible security vulnerability has been identified in Apache Kafka. This requires access to a alterConfig to the cluster resource, or Kafka Connect worker, and the ability to create/modify connectors on it with an arbitrary Kafka client SASL JAAS config and a SASL-based security protocol, which has been possible on Kafka clusters since Apache Kafka 2.0.0 (Kafka Connect 2.3.0). When configuring the broker via config file or AlterConfig command, or connector via the Kafka Kafka Connect REST API, an authenticated operator can set the `sasl.jaas.config` property for any of the connector's Kafka clients to ""com.sun.security.auth.module.LdapLoginModule"", which can be done via the `producer.override.sasl.jaas.config`, `consumer.override.sasl.jaas.config`, or `admin.override.sasl.jaas.config` properties. This will allow the server to connect to the attacker's LDAP server and deserialize the LDAP response, which the attacker can use to execute java deserialization gadget chains on the Kafka connect server. Attacker can cause unrestricted deserialization of untrusted data (or) RCE vulnerability when there are gadgets in the classpath.  Since Apache Kafka 3.0.0, users are allowed to specify these properties in connector configurations for Kafka Connect clusters running with out-of-the-box configurations. Before Apache Kafka 3.0.0, users may not specify these properties unless the Kafka Connect cluster has been reconfigured with a connector client override policy that permits them.  Since Apache Kafka 3.9.1/4.0.0, we have added a system property (""-Dorg.apache.kafka.disallowed.login.modules"") to disable the problematic login modules usage in SASL JAAS configuration. Also by default ""com.sun.security.auth.module.JndiLoginModule,com.sun.security.auth.module.LdapLoginModule"" are disabled in Apache Kafka Connect 3.9.1/4.0.0.   We advise the Kafka users to validate connector configurations and only allow trusted LDAP configurations. Also examine connector dependencies for  vulnerable versions and either upgrade their connectors, upgrading that specific dependency, or removing the connectors as options for remediation. Finally, in addition to leveraging the ""org.apache.kafka.disallowed.login.modules"" system property, Kafka Connect users can also implement their own connector client config override policy, which can be used to control which Kafka client properties can be overridden directly in a connector config and which cannot.  Sonatype's research suggests that this CVE's details differ from those defined at NVD. See https://ossindex.sonatype.org/vulnerability/CVE-2025-27818 for details",OSSINDEX,HIGH,8.699999809265137,CVSS:4.0/AV:N/AC:L/AT:N/PR:L/UI:N/VC:H/VI:H/VA:H/SC:N/SI:N/SA:N,,,,,,,HIGH,23,,,,,,,,
kafka-clients-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",e57ddd02a349770f42d4019e85097dc8,a4f66ca79617470d1355b809675313619bbae45a,pkg:maven/org.apache.kafka/kafka-clients@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2022-34917,"CWE-789 Memory Allocation with Excessive Size Value, CWE-770 Allocation of Resources Without Limits or Throttling","A security vulnerability has been identified in Apache Kafka. It affects all releases since 2.8.0. The vulnerability allows malicious unauthenticated clients to allocate large amounts of memory on brokers. This can lead to brokers hitting OutOfMemoryException and causing denial of service. Example scenarios: - Kafka cluster without authentication: Any clients able to establish a network connection to a broker can trigger the issue. - Kafka cluster with SASL authentication: Any clients able to establish a network connection to a broker, without the need for valid SASL credentials, can trigger the issue. - Kafka cluster with TLS authentication: Only clients able to successfully authenticate via TLS can trigger the issue. We advise the users to upgrade the Kafka installations to one of the 3.2.3, 3.1.2, 3.0.2, 2.8.2 versions.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
kafka-clients-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",e57ddd02a349770f42d4019e85097dc8,a4f66ca79617470d1355b809675313619bbae45a,pkg:maven/org.apache.kafka/kafka-clients@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2024-31141,CWE-269 Improper Privilege Management,"Files or Directories Accessible to External Parties, Improper Privilege Management vulnerability in Apache Kafka Clients.  Apache Kafka Clients accept configuration data for customizing behavior, and includes ConfigProvider plugins in order to manipulate these configurations. Apache Kafka also provides FileConfigProvider, DirectoryConfigProvider, and EnvVarConfigProvider implementations which include the ability to read from disk or environment variables. In applications where Apache Kafka Clients configurations can be specified by an untrusted party, attackers may use these ConfigProviders to read arbitrary contents of the disk and environment variables.  In particular, this flaw may be used in Apache Kafka Connect to escalate from REST API access to filesystem/environment access, which may be undesirable in certain environments, including SaaS products. This issue affects Apache Kafka Clients: from 2.3.0 through 3.5.2, 3.6.2, 3.7.0.   Users with affected applications are recommended to upgrade kafka-clients to version >=3.8.0, and set the JVM system property ""org.apache.kafka.automatic.config.providers=none"". Users of Kafka Connect with one of the listed ConfigProvider implementations specified in their worker config are also recommended to add appropriate ""allowlist.pattern"" and ""allowed.paths"" to restrict their operation to appropriate bounds.   For users of Kafka Clients or Kafka Connect in environments that trust users with disk and environment variable access, it is not recommended to set the system property. For users of the Kafka Broker, Kafka MirrorMaker 2.0, Kafka Streams, and Kafka command-line tools, it is not recommended to set the system property.",OSSINDEX,HIGH,7.099999904632568,CVSS:4.0/AV:N/AC:L/AT:N/PR:L/UI:N/VC:H/VI:N/VA:N/SC:N/SI:N/SA:N,,,,,,,HIGH,23,,,,,,,,
kafka-clients-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",e57ddd02a349770f42d4019e85097dc8,a4f66ca79617470d1355b809675313619bbae45a,pkg:maven/org.apache.kafka/kafka-clients@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2021-38153,CWE-203 Observable Discrepancy,"Some components in Apache Kafka use `Arrays.equals` to validate a password or key, which is vulnerable to timing attacks that make brute force attacks for such credentials more likely to be successful. Users should upgrade to 2.8.1 or higher, or 3.0.0 or higher where this vulnerability has been fixed. The affected versions include Apache Kafka 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.6.1, 2.6.2, 2.7.0, 2.7.1, and 2.8.0.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.9,CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N/E:2.2/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
kafka-clients-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",e57ddd02a349770f42d4019e85097dc8,a4f66ca79617470d1355b809675313619bbae45a,pkg:maven/org.apache.kafka/kafka-clients@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2024-56128,"CWE-303 Incorrect Implementation of Authentication Algorithm, NVD-CWE-Other","Incorrect Implementation of Authentication Algorithm in Apache Kafka's SCRAM implementation.  Issue Summary: Apache Kafka's implementation of the Salted Challenge Response Authentication Mechanism (SCRAM) did not fully adhere to the requirements of RFC 5802 [1]. Specifically, as per RFC 5802, the server must verify that the nonce sent by the client in the second message matches the nonce sent by the server in its first message. However, Kafka's SCRAM implementation did not perform this validation.  Impact: This vulnerability is exploitable only when an attacker has plaintext access to the SCRAM authentication exchange. However, the usage of SCRAM over plaintext is strongly discouraged as it is considered an insecure practice [2]. Apache Kafka recommends deploying SCRAM exclusively with TLS encryption to protect SCRAM exchanges from interception [3]. Deployments using SCRAM with TLS are not affected by this issue.  How to Detect If You Are Impacted: If your deployment uses SCRAM authentication over plaintext communication channels (without TLS encryption), you are likely impacted. To check if TLS is enabled, review your server.properties configuration file for listeners property. If you have SASL_PLAINTEXT in the listeners, then you are likely impacted.  Fix Details: The issue has been addressed by introducing nonce verification in the final message of the SCRAM authentication exchange to ensure compliance with RFC 5802.  Affected Versions: Apache Kafka versions 0.10.2.0 through 3.9.0, excluding the fixed versions below.  Fixed Versions: 3.9.0 3.8.1 3.7.2  Users are advised to upgrade to 3.7.2 or later to mitigate this issue.  Recommendations for Mitigation: Users unable to upgrade to the fixed versions can mitigate the issue by: - Using TLS with SCRAM Authentication: Always deploy SCRAM over TLS to encrypt authentication exchanges and protect against interception. - Considering Alternative Authentication Mechanisms: Evaluate alternative authentication mechanisms, such as PLAIN, Kerberos or OAuth with TLS, which provide additional layers of security.",NVD,,,,MEDIUM,5.3,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N/E:3.9/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
kafka-streams-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-streams/2.8.0/kafka-streams-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",d970c063d51ff97dd34b0cf43e51a13e,c2f9c2bab48a3f62e7a61f51cc5d26d5c8b4a88c,pkg:maven/org.apache.kafka/kafka-streams@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2022-34917,"CWE-789 Memory Allocation with Excessive Size Value, CWE-770 Allocation of Resources Without Limits or Throttling","A security vulnerability has been identified in Apache Kafka. It affects all releases since 2.8.0. The vulnerability allows malicious unauthenticated clients to allocate large amounts of memory on brokers. This can lead to brokers hitting OutOfMemoryException and causing denial of service. Example scenarios: - Kafka cluster without authentication: Any clients able to establish a network connection to a broker can trigger the issue. - Kafka cluster with SASL authentication: Any clients able to establish a network connection to a broker, without the need for valid SASL credentials, can trigger the issue. - Kafka cluster with TLS authentication: Only clients able to successfully authenticate via TLS can trigger the issue. We advise the users to upgrade the Kafka installations to one of the 3.2.3, 3.1.2, 3.0.2, 2.8.2 versions.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
kafka-streams-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-streams/2.8.0/kafka-streams-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",d970c063d51ff97dd34b0cf43e51a13e,c2f9c2bab48a3f62e7a61f51cc5d26d5c8b4a88c,pkg:maven/org.apache.kafka/kafka-streams@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2021-38153,CWE-203 Observable Discrepancy,"Some components in Apache Kafka use `Arrays.equals` to validate a password or key, which is vulnerable to timing attacks that make brute force attacks for such credentials more likely to be successful. Users should upgrade to 2.8.1 or higher, or 3.0.0 or higher where this vulnerability has been fixed. The affected versions include Apache Kafka 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.6.1, 2.6.2, 2.7.0, 2.7.1, and 2.8.0.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.9,CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N/E:2.2/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
kafka-streams-2.8.0.jar,/home/runner/.m2/repository/org/apache/kafka/kafka-streams/2.8.0/kafka-streams-2.8.0.jar,,"The Apache Software License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0.txt",d970c063d51ff97dd34b0cf43e51a13e,c2f9c2bab48a3f62e7a61f51cc5d26d5c8b4a88c,pkg:maven/org.apache.kafka/kafka-streams@2.8.0,cpe:2.3:a:apache:kafka:2.8.0:*:*:*:*:*:*:*,CVE-2024-56128,"CWE-303 Incorrect Implementation of Authentication Algorithm, NVD-CWE-Other","Incorrect Implementation of Authentication Algorithm in Apache Kafka's SCRAM implementation.  Issue Summary: Apache Kafka's implementation of the Salted Challenge Response Authentication Mechanism (SCRAM) did not fully adhere to the requirements of RFC 5802 [1]. Specifically, as per RFC 5802, the server must verify that the nonce sent by the client in the second message matches the nonce sent by the server in its first message. However, Kafka's SCRAM implementation did not perform this validation.  Impact: This vulnerability is exploitable only when an attacker has plaintext access to the SCRAM authentication exchange. However, the usage of SCRAM over plaintext is strongly discouraged as it is considered an insecure practice [2]. Apache Kafka recommends deploying SCRAM exclusively with TLS encryption to protect SCRAM exchanges from interception [3]. Deployments using SCRAM with TLS are not affected by this issue.  How to Detect If You Are Impacted: If your deployment uses SCRAM authentication over plaintext communication channels (without TLS encryption), you are likely impacted. To check if TLS is enabled, review your server.properties configuration file for listeners property. If you have SASL_PLAINTEXT in the listeners, then you are likely impacted.  Fix Details: The issue has been addressed by introducing nonce verification in the final message of the SCRAM authentication exchange to ensure compliance with RFC 5802.  Affected Versions: Apache Kafka versions 0.10.2.0 through 3.9.0, excluding the fixed versions below.  Fixed Versions: 3.9.0 3.8.1 3.7.2  Users are advised to upgrade to 3.7.2 or later to mitigate this issue.  Recommendations for Mitigation: Users unable to upgrade to the fixed versions can mitigate the issue by: - Using TLS with SCRAM Authentication: Always deploy SCRAM over TLS to encrypt authentication exchanges and protect against interception. - Considering Alternative Authentication Mechanisms: Evaluate alternative authentication mechanisms, such as PLAIN, Kerberos or OAuth with TLS, which provide additional layers of security.",NVD,,,,MEDIUM,5.3,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N/E:3.9/RC:R/MAV:A,,,,HIGH,23,,,,,,,,
malli-cli-0.0.5.jar,/home/runner/.m2/repository/com/github/piotr-yuxuan/malli-cli/0.0.5/malli-cli-0.0.5.jar,A Clojure map which implements java.io.Closeable,European Union Public License 1.2 or later: https://joinup.ec.europa.eu/collection/eupl/eupl-text-eupl-12,a1693a8ef2602d631850ad8509075de6,61a5295497b5b8e303ca93890f96222546e8ec15,pkg:maven/com.github.piotr-yuxuan/malli-cli@0.0.5,cpe:2.3:a:github:cli:0.0.5:*:*:*:*:*:*:*,CVE-2024-52308,CWE-77 Improper Neutralization of Special Elements used in a Command ('Command Injection'),"The GitHub CLI version 2.6.1 and earlier are vulnerable to remote code execution through a malicious codespace SSH server when using `gh codespace ssh` or `gh codespace logs` commands. This has been patched in the cli v2.62.0.  Developers connect to remote codespaces through an SSH server running within the devcontainer, which is generally provided through the [default devcontainer image]( https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-... https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration/introduction-to-dev-containers#using-the-default-dev-container-configuration) . GitHub CLI [retrieves SSH connection details]( https://github.com/cli/cli/blob/30066b0042d0c5928d959e288144300cb28196c9/internal/codespaces/rpc/inv... https://github.com/cli/cli/blob/30066b0042d0c5928d959e288144300cb28196c9/internal/codespaces/rpc/invoker.go#L230-L244 ), such as remote username, which is used in [executing `ssh` commands]( https://github.com/cli/cli/blob/e356c69a6f0125cfaac782c35acf77314f18908d/pkg/cmd/codespace/ssh.go#L2... https://github.com/cli/cli/blob/e356c69a6f0125cfaac782c35acf77314f18908d/pkg/cmd/codespace/ssh.go#L263 ) for `gh codespace ssh` or `gh codespace logs` commands.  This exploit occurs when a malicious third-party devcontainer contains a modified SSH server that injects `ssh` arguments within the SSH connection details. `gh codespace ssh` and `gh codespace logs` commands could execute arbitrary code on the user's workstation if the remote username contains something like `-oProxyCommand=""echo hacked"" #`.  The `-oProxyCommand` flag causes `ssh` to execute the provided command while `#` shell comment causes any other `ssh` arguments to be ignored.  In `2.62.0`, the remote username information is being validated before being used.",NVD,,,,CRITICAL,9.6,CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H/E:2.8/RC:R/MAV:A,,,,HIGH,21,,,,,,,,
mulog-prometheus-0.8.2.jar,/home/runner/.m2/repository/com/brunobonacci/mulog-prometheus/0.8.2/mulog-prometheus-0.8.2.jar,A publisher for μ/log to Prometheus.,Apache License 2.0: http://www.apache.org/licenses/LICENSE-2.0,6ad3f44b1bc4940acebbc6a3e8707b2f,5c9d9164f8a646b152f4ffd18a006417ef9559e6,pkg:maven/com.brunobonacci/mulog-prometheus@0.8.2,cpe:2.3:a:prometheus:prometheus:0.8.2:*:*:*:*:*:*:*,CVE-2019-3826,CWE-79 Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting'),"A stored, DOM based, cross-site scripting (XSS) flaw was found in Prometheus before version 2.7.1. An attacker could exploit this by convincing an authenticated user to visit a crafted URL on a Prometheus server, allowing for the execution and persistent storage of arbitrary scripts.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:N/I:P/A:N,MEDIUM,6.1,CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N/E:2.8/RC:R/MAV:A,,,,HIGH,15,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37136,CWE-400 Uncontrolled Resource Consumption,The Bzip2 decompression decoder function doesn't allow setting size restrictions on the decompressed output data (which affects the allocation size used during decompression). All users of Bzip2Decoder are affected. The malicious input can trigger an OOME and so a DoS attack,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37137,CWE-400 Uncontrolled Resource Consumption,The Snappy frame decoder function doesn't restrict the chunk length which may lead to excessive memory usage. Beside this it also may buffer reserved skippable chunks until the whole chunk was received which may lead to excessive memory usage as well. This vulnerability can be triggered by supplying malicious input that decompresses to a very big size (via a network stream or a file) or by sending a huge skippable chunk.,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-41881,CWE-674 Uncontrolled Recursion,"Netty project is an event-driven asynchronous network application framework. In versions prior to 4.1.86.Final, a StackOverflowError can be raised when parsing a malformed crafted message due to an infinite recursion. This issue is patched in version 4.1.86.Final. There is no workaround, except using a custom HaProxyMessageDecoder.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-44487,"CWE-400 Uncontrolled Resource Consumption, NVD-CWE-noinfo","The HTTP/2 protocol allows a denial of service (server resource consumption) because request cancellation can reset many streams quickly, as exploited in the wild in August through October 2023.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,IETF,HTTP/2,HTTP/2 Rapid Reset Attack Vulnerability,2023-10-10,HTTP/2 contains a rapid reset vulnerability that allows for a distributed denial-of-service attack (DDoS).,"Apply mitigations per vendor instructions, follow applicable BOD 22-01 guidance for cloud services, or discontinue use of the product if mitigations are unavailable.",2023-10-31,"This vulnerability affects a common open-source component, third-party library, or protocol used by different products. For more information, please see: HTTP/2 Rapid Reset Vulnerability, CVE-2023-44487 | CISA: https://www.cisa.gov/news-events/alerts/2023/10/10/http2-rapid-reset-vulnerability-cve-2023-44487; https://blog.cloudflare.com/technical-breakdown-http2-rapid-reset-ddos-attack/;  https://nvd.nist.gov/vuln/detail/CVE-2023-44487"
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-43797,CWE-444 Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling'),"Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. Netty prior to version 4.1.71.Final skips control chars when they are present at the beginning / end of the header name. It should instead fail fast as these are not allowed by the spec and could lead to HTTP request smuggling. Failing to do the validation might cause netty to ""sanitize"" header names before it forward these to another remote system when used as proxy. This remote system can't see the invalid usage anymore, and therefore does not do the validation itself. Users should upgrade to version 4.1.71.Final.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:N/I:P/A:N,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:N/E:2.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-41915,CWE-113 Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Request/Response Splitting'),"Netty project is an event-driven asynchronous network application framework. Starting in version 4.1.83.Final and prior to 4.1.86.Final, when calling `DefaultHttpHeadesr.set` with an _iterator_ of values, header value validation was not performed, allowing malicious header values in the iterator to perform HTTP Response Splitting. This issue has been patched in version 4.1.86.Final. Integrators can work around the issue by changing the `DefaultHttpHeaders.set(CharSequence, Iterator<?>)` call, into a `remove()` call, and call `add()` in a loop over the iterator of values.  Sonatype's research suggests that this CVE's details differ from those defined at NVD. See https://ossindex.sonatype.org/vulnerability/CVE-2022-41915 for details",OSSINDEX,,,,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-34462,"CWE-400 Uncontrolled Resource Consumption, CWE-770 Allocation of Resources Without Limits or Throttling","Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. The `SniHandler` can allocate up to 16MB of heap for each channel during the TLS handshake. When the handler or the channel does not have an idle timeout, it can be used to make a TCP server using the `SniHandler` to allocate 16MB of heap. The `SniHandler` class is a handler that waits for the TLS handshake to configure a `SslHandler` according to the indicated server name by the `ClientHello` record. For this matter it allocates a `ByteBuf` using the value defined in the `ClientHello` record. Normally the value of the packet should be smaller than the handshake packet but there are not checks done here and the way the code is written, it is possible to craft a packet that makes the `SslClientHelloHandler`. This vulnerability has been fixed in version 4.1.94.Final.",NVD,,,,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:2.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-24823,"CWE-378 Creation of Temporary File With Insecure Permissions, CWE-379 Creation of Temporary File in Directory with Insecure Permissions, CWE-668 Exposure of Resource to Wrong Sphere","Netty is an open-source, asynchronous event-driven network application framework. The package `io.netty:netty-codec-http` prior to version 4.1.77.Final contains an insufficient fix for CVE-2021-21290. When Netty's multipart decoders are used local information disclosure can occur via the local system temporary directory if temporary storing uploads on the disk is enabled. This only impacts applications running on Java version 6 and lower. Additionally, this vulnerability impacts code running on Unix-like systems, and very old versions of Mac OSX and Windows as they all share the system temporary directory between all users. Version 4.1.77.Final contains a patch for this vulnerability. As a workaround, specify one's own `java.io.tmpdir` when starting the JVM or use DefaultHttpDataFactory.setBaseDir(...) to set the directory to something that is only readable by the current user.",NVD,LOW,1.9,/AV:L/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N/E:1.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,e67c68c02244a036e4ec8c838783d1ce,d4d2fccea88c80e56d59ce1053c53df0f9f4f5db,pkg:maven/io.netty/netty-codec@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2025-25193,CWE-400 Uncontrolled Resource Consumption,"Netty, an asynchronous, event-driven network application framework, has a vulnerability in versions up to and including 4.1.118.Final. An unsafe reading of environment file could potentially cause a denial of service in Netty. When loaded on an Windows application, Netty attempts to load a file that does not exist. If an attacker creates such a large file, the Netty application crash. A similar issue was previously reported as CVE-2024-47535. This issue was fixed, but the fix was incomplete in that null-bytes were not counted against the input limit. Commit d1fbda62d3a47835d3fb35db8bd42ecc205a5386 contains an updated fix.",NVD,,,,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:1.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37136,CWE-400 Uncontrolled Resource Consumption,The Bzip2 decompression decoder function doesn't allow setting size restrictions on the decompressed output data (which affects the allocation size used during decompression). All users of Bzip2Decoder are affected. The malicious input can trigger an OOME and so a DoS attack,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37137,CWE-400 Uncontrolled Resource Consumption,The Snappy frame decoder function doesn't restrict the chunk length which may lead to excessive memory usage. Beside this it also may buffer reserved skippable chunks until the whole chunk was received which may lead to excessive memory usage as well. This vulnerability can be triggered by supplying malicious input that decompresses to a very big size (via a network stream or a file) or by sending a huge skippable chunk.,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-41881,CWE-674 Uncontrolled Recursion,"Netty project is an event-driven asynchronous network application framework. In versions prior to 4.1.86.Final, a StackOverflowError can be raised when parsing a malformed crafted message due to an infinite recursion. This issue is patched in version 4.1.86.Final. There is no workaround, except using a custom HaProxyMessageDecoder.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-44487,"CWE-400 Uncontrolled Resource Consumption, NVD-CWE-noinfo","The HTTP/2 protocol allows a denial of service (server resource consumption) because request cancellation can reset many streams quickly, as exploited in the wild in August through October 2023.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,31,IETF,HTTP/2,HTTP/2 Rapid Reset Attack Vulnerability,2023-10-10,HTTP/2 contains a rapid reset vulnerability that allows for a distributed denial-of-service attack (DDoS).,"Apply mitigations per vendor instructions, follow applicable BOD 22-01 guidance for cloud services, or discontinue use of the product if mitigations are unavailable.",2023-10-31,"This vulnerability affects a common open-source component, third-party library, or protocol used by different products. For more information, please see: HTTP/2 Rapid Reset Vulnerability, CVE-2023-44487 | CISA: https://www.cisa.gov/news-events/alerts/2023/10/10/http2-rapid-reset-vulnerability-cve-2023-44487; https://blog.cloudflare.com/technical-breakdown-http2-rapid-reset-ddos-attack/;  https://nvd.nist.gov/vuln/detail/CVE-2023-44487"
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-43797,CWE-444 Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling'),"Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. Netty prior to version 4.1.71.Final skips control chars when they are present at the beginning / end of the header name. It should instead fail fast as these are not allowed by the spec and could lead to HTTP request smuggling. Failing to do the validation might cause netty to ""sanitize"" header names before it forward these to another remote system when used as proxy. This remote system can't see the invalid usage anymore, and therefore does not do the validation itself. Users should upgrade to version 4.1.71.Final.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:N/I:P/A:N,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:N/E:2.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-34462,"CWE-400 Uncontrolled Resource Consumption, CWE-770 Allocation of Resources Without Limits or Throttling","Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. The `SniHandler` can allocate up to 16MB of heap for each channel during the TLS handshake. When the handler or the channel does not have an idle timeout, it can be used to make a TCP server using the `SniHandler` to allocate 16MB of heap. The `SniHandler` class is a handler that waits for the TLS handshake to configure a `SslHandler` according to the indicated server name by the `ClientHello` record. For this matter it allocates a `ByteBuf` using the value defined in the `ClientHello` record. Normally the value of the packet should be smaller than the handshake packet but there are not checks done here and the way the code is written, it is possible to craft a packet that makes the `SslClientHelloHandler`. This vulnerability has been fixed in version 4.1.94.Final.",NVD,,,,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:2.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-24823,"CWE-378 Creation of Temporary File With Insecure Permissions, CWE-379 Creation of Temporary File in Directory with Insecure Permissions, CWE-668 Exposure of Resource to Wrong Sphere","Netty is an open-source, asynchronous event-driven network application framework. The package `io.netty:netty-codec-http` prior to version 4.1.77.Final contains an insufficient fix for CVE-2021-21290. When Netty's multipart decoders are used local information disclosure can occur via the local system temporary directory if temporary storing uploads on the disk is enabled. This only impacts applications running on Java version 6 and lower. Additionally, this vulnerability impacts code running on Unix-like systems, and very old versions of Mac OSX and Windows as they all share the system temporary directory between all users. Version 4.1.77.Final contains a patch for this vulnerability. As a workaround, specify one's own `java.io.tmpdir` when starting the JVM or use DefaultHttpDataFactory.setBaseDir(...) to set the directory to something that is only readable by the current user.",NVD,LOW,1.9,/AV:L/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N/E:1.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2025-25193,CWE-400 Uncontrolled Resource Consumption,"Netty, an asynchronous, event-driven network application framework, has a vulnerability in versions up to and including 4.1.118.Final. An unsafe reading of environment file could potentially cause a denial of service in Netty. When loaded on an Windows application, Netty attempts to load a file that does not exist. If an attacker creates such a large file, the Netty application crash. A similar issue was previously reported as CVE-2024-47535. This issue was fixed, but the fix was incomplete in that null-bytes were not counted against the input limit. Commit d1fbda62d3a47835d3fb35db8bd42ecc205a5386 contains an updated fix.",NVD,,,,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:1.8/RC:R/MAV:A,,,,HIGH,31,,,,,,,,
netty-codec-http-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,832216f9bdc53c1346a5e46f9501ffc8,f8c9b159dcb76452dc98a370a5511ff993670419,pkg:maven/io.netty/netty-codec-http@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2024-29025,CWE-770 Allocation of Resources Without Limits or Throttling,"Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. The `HttpPostRequestDecoder` can be tricked to accumulate data. While the decoder can store items on the disk if configured so, there are no limits to the number of fields the form can have, an attacher can send a chunked post consisting of many small fields that will be accumulated in the `bodyListHttpData` list. The decoder cumulates bytes in the `undecodedChunk` buffer until it can decode a field, this field can cumulate data without limits. This vulnerability is fixed in 4.1.108.Final.  Sonatype's research suggests that this CVE's details differ from those defined at NVD. See https://ossindex.sonatype.org/vulnerability/CVE-2024-29025 for details",OSSINDEX,,,,MEDIUM,5.300000190734863,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L,,,,HIGH,31,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37136,CWE-400 Uncontrolled Resource Consumption,The Bzip2 decompression decoder function doesn't allow setting size restrictions on the decompressed output data (which affects the allocation size used during decompression). All users of Bzip2Decoder are affected. The malicious input can trigger an OOME and so a DoS attack,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37137,CWE-400 Uncontrolled Resource Consumption,The Snappy frame decoder function doesn't restrict the chunk length which may lead to excessive memory usage. Beside this it also may buffer reserved skippable chunks until the whole chunk was received which may lead to excessive memory usage as well. This vulnerability can be triggered by supplying malicious input that decompresses to a very big size (via a network stream or a file) or by sending a huge skippable chunk.,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-41881,CWE-674 Uncontrolled Recursion,"Netty project is an event-driven asynchronous network application framework. In versions prior to 4.1.86.Final, a StackOverflowError can be raised when parsing a malformed crafted message due to an infinite recursion. This issue is patched in version 4.1.86.Final. There is no workaround, except using a custom HaProxyMessageDecoder.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-44487,"CWE-400 Uncontrolled Resource Consumption, NVD-CWE-noinfo","The HTTP/2 protocol allows a denial of service (server resource consumption) because request cancellation can reset many streams quickly, as exploited in the wild in August through October 2023.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,IETF,HTTP/2,HTTP/2 Rapid Reset Attack Vulnerability,2023-10-10,HTTP/2 contains a rapid reset vulnerability that allows for a distributed denial-of-service attack (DDoS).,"Apply mitigations per vendor instructions, follow applicable BOD 22-01 guidance for cloud services, or discontinue use of the product if mitigations are unavailable.",2023-10-31,"This vulnerability affects a common open-source component, third-party library, or protocol used by different products. For more information, please see: HTTP/2 Rapid Reset Vulnerability, CVE-2023-44487 | CISA: https://www.cisa.gov/news-events/alerts/2023/10/10/http2-rapid-reset-vulnerability-cve-2023-44487; https://blog.cloudflare.com/technical-breakdown-http2-rapid-reset-ddos-attack/;  https://nvd.nist.gov/vuln/detail/CVE-2023-44487"
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2024-47535,CWE-400 Uncontrolled Resource Consumption,"Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. An unsafe reading of environment file could potentially cause a denial of service in Netty. When loaded on an Windows application, Netty attempts to load a file that does not exist. If an attacker creates such a large file, the Netty application crashes. This vulnerability is fixed in 4.1.115.",OSSINDEX,MEDIUM,6.800000190734863,CVSS:4.0/AV:L/AC:L/AT:N/PR:L/UI:N/VC:N/VI:N/VA:H/SC:N/SI:N/SA:L,,,,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-43797,CWE-444 Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling'),"Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. Netty prior to version 4.1.71.Final skips control chars when they are present at the beginning / end of the header name. It should instead fail fast as these are not allowed by the spec and could lead to HTTP request smuggling. Failing to do the validation might cause netty to ""sanitize"" header names before it forward these to another remote system when used as proxy. This remote system can't see the invalid usage anymore, and therefore does not do the validation itself. Users should upgrade to version 4.1.71.Final.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:N/I:P/A:N,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:N/E:2.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-34462,"CWE-400 Uncontrolled Resource Consumption, CWE-770 Allocation of Resources Without Limits or Throttling","Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. The `SniHandler` can allocate up to 16MB of heap for each channel during the TLS handshake. When the handler or the channel does not have an idle timeout, it can be used to make a TCP server using the `SniHandler` to allocate 16MB of heap. The `SniHandler` class is a handler that waits for the TLS handshake to configure a `SslHandler` according to the indicated server name by the `ClientHello` record. For this matter it allocates a `ByteBuf` using the value defined in the `ClientHello` record. Normally the value of the packet should be smaller than the handshake packet but there are not checks done here and the way the code is written, it is possible to craft a packet that makes the `SslClientHelloHandler`. This vulnerability has been fixed in version 4.1.94.Final.",NVD,,,,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:2.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-24823,"CWE-378 Creation of Temporary File With Insecure Permissions, CWE-379 Creation of Temporary File in Directory with Insecure Permissions, CWE-668 Exposure of Resource to Wrong Sphere","Netty is an open-source, asynchronous event-driven network application framework. The package `io.netty:netty-codec-http` prior to version 4.1.77.Final contains an insufficient fix for CVE-2021-21290. When Netty's multipart decoders are used local information disclosure can occur via the local system temporary directory if temporary storing uploads on the disk is enabled. This only impacts applications running on Java version 6 and lower. Additionally, this vulnerability impacts code running on Unix-like systems, and very old versions of Mac OSX and Windows as they all share the system temporary directory between all users. Version 4.1.77.Final contains a patch for this vulnerability. As a workaround, specify one's own `java.io.tmpdir` when starting the JVM or use DefaultHttpDataFactory.setBaseDir(...) to set the directory to something that is only readable by the current user.",NVD,LOW,1.9,/AV:L/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N/E:1.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-common-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,239ec75d3d5d9bffeb18a017de99e08c,e1206b46384d4dcbecee2901f18ce65ecf02e8a4,pkg:maven/io.netty/netty-common@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2025-25193,CWE-400 Uncontrolled Resource Consumption,"Netty, an asynchronous, event-driven network application framework, has a vulnerability in versions up to and including 4.1.118.Final. An unsafe reading of environment file could potentially cause a denial of service in Netty. When loaded on an Windows application, Netty attempts to load a file that does not exist. If an attacker creates such a large file, the Netty application crash. A similar issue was previously reported as CVE-2024-47535. This issue was fixed, but the fix was incomplete in that null-bytes were not counted against the input limit. Commit d1fbda62d3a47835d3fb35db8bd42ecc205a5386 contains an updated fix.",NVD,,,,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:1.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37136,CWE-400 Uncontrolled Resource Consumption,The Bzip2 decompression decoder function doesn't allow setting size restrictions on the decompressed output data (which affects the allocation size used during decompression). All users of Bzip2Decoder are affected. The malicious input can trigger an OOME and so a DoS attack,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-37137,CWE-400 Uncontrolled Resource Consumption,The Snappy frame decoder function doesn't restrict the chunk length which may lead to excessive memory usage. Beside this it also may buffer reserved skippable chunks until the whole chunk was received which may lead to excessive memory usage as well. This vulnerability can be triggered by supplying malicious input that decompresses to a very big size (via a network stream or a file) or by sending a huge skippable chunk.,NVD,MEDIUM,5.0,/AV:N/AC:L/Au:N/C:N/I:N/A:P,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-41881,CWE-674 Uncontrolled Recursion,"Netty project is an event-driven asynchronous network application framework. In versions prior to 4.1.86.Final, a StackOverflowError can be raised when parsing a malformed crafted message due to an infinite recursion. This issue is patched in version 4.1.86.Final. There is no workaround, except using a custom HaProxyMessageDecoder.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-44487,"CWE-400 Uncontrolled Resource Consumption, NVD-CWE-noinfo","The HTTP/2 protocol allows a denial of service (server resource consumption) because request cancellation can reset many streams quickly, as exploited in the wild in August through October 2023.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,29,IETF,HTTP/2,HTTP/2 Rapid Reset Attack Vulnerability,2023-10-10,HTTP/2 contains a rapid reset vulnerability that allows for a distributed denial-of-service attack (DDoS).,"Apply mitigations per vendor instructions, follow applicable BOD 22-01 guidance for cloud services, or discontinue use of the product if mitigations are unavailable.",2023-10-31,"This vulnerability affects a common open-source component, third-party library, or protocol used by different products. For more information, please see: HTTP/2 Rapid Reset Vulnerability, CVE-2023-44487 | CISA: https://www.cisa.gov/news-events/alerts/2023/10/10/http2-rapid-reset-vulnerability-cve-2023-44487; https://blog.cloudflare.com/technical-breakdown-http2-rapid-reset-ddos-attack/;  https://nvd.nist.gov/vuln/detail/CVE-2023-44487"
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2021-43797,CWE-444 Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling'),"Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. Netty prior to version 4.1.71.Final skips control chars when they are present at the beginning / end of the header name. It should instead fail fast as these are not allowed by the spec and could lead to HTTP request smuggling. Failing to do the validation might cause netty to ""sanitize"" header names before it forward these to another remote system when used as proxy. This remote system can't see the invalid usage anymore, and therefore does not do the validation itself. Users should upgrade to version 4.1.71.Final.",NVD,MEDIUM,4.3,/AV:N/AC:M/Au:N/C:N/I:P/A:N,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:N/E:2.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2023-34462,"CWE-400 Uncontrolled Resource Consumption, CWE-770 Allocation of Resources Without Limits or Throttling","Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients. The `SniHandler` can allocate up to 16MB of heap for each channel during the TLS handshake. When the handler or the channel does not have an idle timeout, it can be used to make a TCP server using the `SniHandler` to allocate 16MB of heap. The `SniHandler` class is a handler that waits for the TLS handshake to configure a `SslHandler` according to the indicated server name by the `ClientHello` record. For this matter it allocates a `ByteBuf` using the value defined in the `ClientHello` record. Normally the value of the packet should be smaller than the handshake packet but there are not checks done here and the way the code is written, it is possible to craft a packet that makes the `SslClientHelloHandler`. This vulnerability has been fixed in version 4.1.94.Final.",NVD,,,,MEDIUM,6.5,CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:2.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2022-24823,"CWE-378 Creation of Temporary File With Insecure Permissions, CWE-379 Creation of Temporary File in Directory with Insecure Permissions, CWE-668 Exposure of Resource to Wrong Sphere","Netty is an open-source, asynchronous event-driven network application framework. The package `io.netty:netty-codec-http` prior to version 4.1.77.Final contains an insufficient fix for CVE-2021-21290. When Netty's multipart decoders are used local information disclosure can occur via the local system temporary directory if temporary storing uploads on the disk is enabled. This only impacts applications running on Java version 6 and lower. Additionally, this vulnerability impacts code running on Unix-like systems, and very old versions of Mac OSX and Windows as they all share the system temporary directory between all users. Version 4.1.77.Final contains a patch for this vulnerability. As a workaround, specify one's own `java.io.tmpdir` when starting the JVM or use DefaultHttpDataFactory.setBaseDir(...) to set the directory to something that is only readable by the current user.",NVD,LOW,1.9,/AV:L/AC:M/Au:N/C:P/I:N/A:N,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N/E:1.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
netty-transport-4.1.63.Final.jar,/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar,Netty is an asynchronous event-driven network application framework for    rapid development of maintainable high performance protocol servers and    clients.,https://www.apache.org/licenses/LICENSE-2.0,a40109a795b224dbac09b285f057dbd7,09a8bbe1ba082c9434e6f524d3864a53f340f2df,pkg:maven/io.netty/netty-transport@4.1.63.Final,cpe:2.3:a:netty:netty:4.1.63:*:*:*:*:*:*:*,CVE-2025-25193,CWE-400 Uncontrolled Resource Consumption,"Netty, an asynchronous, event-driven network application framework, has a vulnerability in versions up to and including 4.1.118.Final. An unsafe reading of environment file could potentially cause a denial of service in Netty. When loaded on an Windows application, Netty attempts to load a file that does not exist. If an attacker creates such a large file, the Netty application crash. A similar issue was previously reported as CVE-2024-47535. This issue was fixed, but the fix was incomplete in that null-bytes were not counted against the input limit. Commit d1fbda62d3a47835d3fb35db8bd42ecc205a5386 contains an updated fix.",NVD,,,,MEDIUM,5.5,CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:1.8/RC:R/MAV:A,,,,HIGH,29,,,,,,,,
snappy-java-1.1.8.1.jar,/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.1/snappy-java-1.1.8.1.jar,snappy-java: A fast compression/decompression library,Apache-2.0: https://www.apache.org/licenses/LICENSE-2.0.html,6b9c4f220701bb7c39d0843095bb3402,d30aaf4d41d6ff0c760c8931d3b8dafc0293c91a,pkg:maven/org.xerial.snappy/snappy-java@1.1.8.1,cpe:2.3:a:xerial:snappy-java:1.1.8.1:*:*:*:*:*:*:*,CVE-2023-34453,CWE-190 Integer Overflow or Wraparound,"snappy-java is a fast compressor/decompressor for Java. Due to unchecked multiplications, an integer overflow may occur in versions prior to 1.1.10.1, causing a fatal error.  The function `shuffle(int[] input)` in the file `BitShuffle.java` receives an array of integers and applies a bit shuffle on it. It does so by multiplying the length by 4 and passing it to the natively compiled shuffle function. Since the length is not tested, the multiplication by four can cause an integer overflow and become a smaller value than the true size, or even zero or negative. In the case of a negative value, a `java.lang.NegativeArraySizeException` exception will raise, which can crash the program. In a case of a value that is zero or too small, the code that afterwards references the shuffled array will assume a bigger size of the array, which might cause exceptions such as `java.lang.ArrayIndexOutOfBoundsException`.  The same issue exists also when using the `shuffle` functions that receive a double, float, long and short, each using a different multiplier that may cause the same issue.  Version 1.1.10.1 contains a patch for this vulnerability.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,48,,,,,,,,
snappy-java-1.1.8.1.jar,/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.1/snappy-java-1.1.8.1.jar,snappy-java: A fast compression/decompression library,Apache-2.0: https://www.apache.org/licenses/LICENSE-2.0.html,6b9c4f220701bb7c39d0843095bb3402,d30aaf4d41d6ff0c760c8931d3b8dafc0293c91a,pkg:maven/org.xerial.snappy/snappy-java@1.1.8.1,cpe:2.3:a:xerial:snappy-java:1.1.8.1:*:*:*:*:*:*:*,CVE-2023-34454,CWE-190 Integer Overflow or Wraparound,"snappy-java is a fast compressor/decompressor for Java. Due to unchecked multiplications, an integer overflow may occur in versions prior to 1.1.10.1, causing an unrecoverable fatal error.  The function `compress(char[] input)` in the file `Snappy.java` receives an array of characters and compresses it. It does so by multiplying the length by 2 and passing it to the rawCompress` function.  Since the length is not tested, the multiplication by two can cause an integer overflow and become negative. The rawCompress function then uses the received length and passes it to the natively compiled maxCompressedLength function, using the returned value to allocate a byte array.  Since the maxCompressedLength function treats the length as an unsigned integer, it doesn’t care that it is negative, and it returns a valid value, which is casted to a signed integer by the Java engine. If the result is negative, a `java.lang.NegativeArraySizeException` exception will be raised while trying to allocate the array `buf`. On the other side, if the result is positive, the `buf` array will successfully be allocated, but its size might be too small to use for the compression, causing a fatal Access Violation error.  The same issue exists also when using the `compress` functions that receive double, float, int, long and short, each using a different multiplier that may cause the same issue. The issue most likely won’t occur when using a byte array, since creating a byte array of size 0x80000000 (or any other negative value) is impossible in the first place.  Version 1.1.10.1 contains a patch for this issue.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,48,,,,,,,,
snappy-java-1.1.8.1.jar,/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.1/snappy-java-1.1.8.1.jar,snappy-java: A fast compression/decompression library,Apache-2.0: https://www.apache.org/licenses/LICENSE-2.0.html,6b9c4f220701bb7c39d0843095bb3402,d30aaf4d41d6ff0c760c8931d3b8dafc0293c91a,pkg:maven/org.xerial.snappy/snappy-java@1.1.8.1,cpe:2.3:a:xerial:snappy-java:1.1.8.1:*:*:*:*:*:*:*,CVE-2023-34455,CWE-770 Allocation of Resources Without Limits or Throttling,"snappy-java is a fast compressor/decompressor for Java. Due to use of an unchecked chunk length, an unrecoverable fatal error can occur in versions prior to 1.1.10.1.  The code in the function hasNextChunk in the fileSnappyInputStream.java checks if a given stream has more chunks to read. It does that by attempting to read 4 bytes. If it wasn’t possible to read the 4 bytes, the function returns false. Otherwise, if 4 bytes were available, the code treats them as the length of the next chunk.  In the case that the `compressed` variable is null, a byte array is allocated with the size given by the input data. Since the code doesn’t test the legality of the `chunkSize` variable, it is possible to pass a negative number (such as 0xFFFFFFFF which is -1), which will cause the code to raise a `java.lang.NegativeArraySizeException` exception. A worse case would happen when passing a huge positive value (such as 0x7FFFFFFF), which would raise the fatal `java.lang.OutOfMemoryError` error.  Version 1.1.10.1 contains a patch for this issue.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,48,,,,,,,,
snappy-java-1.1.8.1.jar,/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.1/snappy-java-1.1.8.1.jar,snappy-java: A fast compression/decompression library,Apache-2.0: https://www.apache.org/licenses/LICENSE-2.0.html,6b9c4f220701bb7c39d0843095bb3402,d30aaf4d41d6ff0c760c8931d3b8dafc0293c91a,pkg:maven/org.xerial.snappy/snappy-java@1.1.8.1,cpe:2.3:a:xerial:snappy-java:1.1.8.1:*:*:*:*:*:*:*,CVE-2023-43642,CWE-770 Allocation of Resources Without Limits or Throttling,"snappy-java is a Java port of the snappy, a fast C++ compresser/decompresser developed by Google. The SnappyInputStream was found to be vulnerable to Denial of Service (DoS) attacks when decompressing data with a too large chunk size. Due to missing upper bound check on chunk length, an unrecoverable fatal error can occur. All versions of snappy-java including the latest released version 1.1.10.3 are vulnerable to this issue. A fix has been introduced in commit `9f8c3cf74` which will be included in the 1.1.10.4 release. Users are advised to upgrade. Users unable to upgrade should only accept compressed data from trusted sources.",NVD,,,,HIGH,7.5,CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H/E:3.9/RC:R/MAV:A,,,,HIGH,48,,,,,,,,
